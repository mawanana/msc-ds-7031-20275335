{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a033d5a-9658-43f8-91d3-e44269d29ee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Month'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])  \u001b[38;5;66;03m# Select only numeric columns\u001b[39;00m\n\u001b[1;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProductivity\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Exclude the target variable\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exclude non-numeric columns\u001b[39;00m\n\u001b[1;32m     28\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateofWork\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Exclude non-numeric columns\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Scale features\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Month'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Import additional libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Sample02.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "df['Productivity'] = df['ExtraKilos'] / df['Area (Ha)']\n",
    "df['DateofWork'] = pd.to_datetime(df['DateofWork'])\n",
    "df['Month'] = df['DateofWork'].dt.to_period('M').dt.strftime('%Y-%m')\n",
    "df = pd.get_dummies(df, columns=['Division'])\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "X = df.select_dtypes(include=[np.number])  # Select only numeric columns\n",
    "X = X.drop(['Productivity'], axis=1)  # Exclude the target variable\n",
    "X = X.drop(['Month'], axis=1)  # Exclude non-numeric columns\n",
    "X = X.drop(['DateofWork'], axis=1)  # Exclude non-numeric columns\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Initialize target variable and variables for evaluation\n",
    "y = df['Productivity']\n",
    "division_columns = [col for col in df.columns if col.startswith('Division')]\n",
    "X_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(X_pca.shape[1])])\n",
    "X_final = pd.concat([X_pca, df[['Month']]], axis=1)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "decision_tree_rmse = []\n",
    "random_forest_rmse = []\n",
    "linear_regression_rmse = []\n",
    "\n",
    "# Number of Bootstrapped samples\n",
    "n_samples = 100\n",
    "\n",
    "# Perform Bootstrapping and model evaluation\n",
    "for _ in range(n_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=np.random.randint(100))\n",
    "\n",
    "    # Decision Tree\n",
    "    dt = DecisionTreeRegressor()\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred_dt = dt.predict(X_test)\n",
    "    decision_tree_rmse.append(np.sqrt(mean_squared_error(y_test, y_pred_dt)))\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    random_forest_rmse.append(np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "\n",
    "    # Linear Regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "    linear_regression_rmse.append(np.sqrt(mean_squared_error(y_test, y_pred_lr)))\n",
    "\n",
    "# Evaluate and compare models\n",
    "print(\"Decision Tree RMSE:\", np.mean(decision_tree_rmse))\n",
    "print(\"Random Forest RMSE:\", np.mean(random_forest_rmse))\n",
    "print(\"Linear Regression RMSE:\", np.mean(linear_regression_rmse))\n",
    "\n",
    "# Visualize ExtraKilos/Area (Ha) by Division over time\n",
    "# Create a line plot for each division\n",
    "\n",
    "# Define the date range from January 2012 to December 2015\n",
    "start_date = pd.to_datetime(\"2012-01-01\")\n",
    "end_date = pd.to_datetime(\"2015-12-31\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\", len(division_columns))\n",
    "\n",
    "# Generate month labels for the entire duration period\n",
    "month_labels = [start_date + pd.DateOffset(months=i) for i in range(48)]  # 48 months from Jan 2012 to Dec 2015\n",
    "\n",
    "for division_column in division_columns:\n",
    "    division_name = division_column.split(\"_\")[1]\n",
    "    division_data = df[df[division_column] == 1]\n",
    "\n",
    "    # Filter the data for the specified date range\n",
    "    division_data = division_data[(division_data['DateofWork'] >= start_date) & (division_data['DateofWork'] <= end_date)]\n",
    "    \n",
    "    sns.lineplot(data=division_data, x='Month', y='Productivity', label=division_name)\n",
    "\n",
    "plt.xlabel('Date of Work (Month) from 2012-01 to 2015-12')\n",
    "plt.xticks(range(len(month_labels)), [label.strftime('%b %Y') for label in month_labels], rotation=45)\n",
    "plt.ylabel('ExtraKilos/Area (Ha)')\n",
    "plt.title('ExtraKilos/Area (Ha) by Division over Time')\n",
    "plt.legend(title='Division')\n",
    "\n",
    "plt.savefig('ExtraKilos-Area (Ha) by Division over Time.png')\n",
    "plt.show()\n",
    "\n",
    "# Summarize knowledge gained\n",
    "# Discuss insights, model comparisons, and the updated visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cce1d0-9f2a-4833-8522-d92c37996e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Cross-Validation RMSE: Mean = -0.00026461174548713946 , Std = 0.0003462897514071199\n",
      "Random Forest Cross-Validation RMSE: Mean = -0.0002477974218307665 , Std = 0.0001375604061824433\n",
      "Linear Regression Cross-Validation RMSE: Mean = -7.638616046525527e-28 , Std = 4.489140051470814e-28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Cross-validation\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Decision Tree Cross-validation\n",
    "dt_cv = DecisionTreeRegressor()\n",
    "dt_cv_scores = cross_val_score(dt_cv, X, y, cv=5, scoring=scorer)\n",
    "print(\"Decision Tree Cross-Validation RMSE: Mean =\", np.mean(dt_cv_scores), \", Std =\", np.std(dt_cv_scores))\n",
    "\n",
    "# Random Forest Cross-validation\n",
    "rf_cv = RandomForestRegressor()\n",
    "rf_cv_scores = cross_val_score(rf_cv, X, y, cv=5, scoring=scorer)\n",
    "print(\"Random Forest Cross-Validation RMSE: Mean =\", np.mean(rf_cv_scores), \", Std =\", np.std(rf_cv_scores))\n",
    "\n",
    "# Linear Regression Cross-validation\n",
    "lr_cv = LinearRegression()\n",
    "lr_cv_scores = cross_val_score(lr_cv, X, y, cv=5, scoring=scorer)\n",
    "print(\"Linear Regression Cross-Validation RMSE: Mean =\", np.mean(lr_cv_scores), \", Std =\", np.std(lr_cv_scores))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14c5d954-13f0-4e80-b805-88cadf062780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: Mean = 0.00026259879601631456 , Std = 0.000347903630748269\n",
      "Random Forest RMSE: Mean = 0.00023072295991186085 , Std = 0.00012362108239909083\n",
      "Linear Regression RMSE: Mean = 7.638616046525527e-28 , Std = 4.489140051470814e-28\n",
      "Decision Tree R-squared: Mean = 0.9999953096146583 , Std = 6.47982544799448e-06\n",
      "Random Forest R-squared: Mean = 0.9999963051668317 , Std = 2.1410814171078205e-06\n",
      "Linear Regression R-squared: Mean = 1.0 , Std = 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "dt = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Initialize a scorer (e.g., Mean Squared Error, you can choose other metrics)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Evaluate models using cross-validation\n",
    "dt_cv_scores = -cross_val_score(dt, X, y, cv=5, scoring=scorer)\n",
    "rf_cv_scores = -cross_val_score(rf, X, y, cv=5, scoring=scorer)\n",
    "lr_cv_scores = -cross_val_score(lr, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "# Print and compare the results\n",
    "print(\"Decision Tree RMSE: Mean =\", np.mean(dt_cv_scores), \", Std =\", np.std(dt_cv_scores))\n",
    "print(\"Random Forest RMSE: Mean =\", np.mean(rf_cv_scores), \", Std =\", np.std(rf_cv_scores))\n",
    "print(\"Linear Regression RMSE: Mean =\", np.mean(lr_cv_scores), \", Std =\", np.std(lr_cv_scores))\n",
    "\n",
    "# Additional metrics if needed (e.g., R-squared)\n",
    "dt_r2_scores = cross_val_score(dt, X, y, cv=5, scoring='r2')\n",
    "rf_r2_scores = cross_val_score(rf, X, y, cv=5, scoring='r2')\n",
    "lr_r2_scores = cross_val_score(lr, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(\"Decision Tree R-squared: Mean =\", np.mean(dt_r2_scores), \", Std =\", np.std(dt_r2_scores))\n",
    "print(\"Random Forest R-squared: Mean =\", np.mean(rf_r2_scores), \", Std =\", np.std(rf_r2_scores))\n",
    "print(\"Linear Regression R-squared: Mean =\", np.mean(lr_r2_scores), \", Std =\", np.std(lr_r2_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75176893-4479-41e0-bfd0-630f9f741a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m y_proba_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# y_proba_lr = lr.predict(X_test)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Assuming 'y' is binary (0 or 1)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m fpr_dt, tpr_dt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_proba_dt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m fpr_rf, tpr_rf, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_test, y_proba_rf)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate AUC\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1095\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    994\u001b[0m     {\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m ):\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1095\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Msc_project/msc-ds-7031-20275335/venv/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:804\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    802\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    806\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    807\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "dt = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "# lr = LinearRegression()  # Note: Linear Regression might not be suitable for binary classification\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit models\n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_proba_dt = dt.predict(X_test)\n",
    "y_proba_rf = rf.predict(X_test)\n",
    "# y_proba_lr = lr.predict(X_test)\n",
    "\n",
    "# Assuming 'y' is binary (0 or 1)\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_proba_dt)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "# fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "# roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {roc_auc_dt:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "# plt.plot(fpr_lr, tpr_lr, label=f'Linear Regression (AUC = {roc_auc_lr:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line for random model\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd69a3b-e895-413f-b9de-e7de35f3e271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
